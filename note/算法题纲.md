
## 二、理论部分  

### 1) 算法的基本概念和性质  
**算法**是为解决特定问题而定义的**有限、确定、可行**的指令序列。其基本性质包括：  
- **有穷性**：执行步骤有限，总在有限步后终止；  
- **确定性**：每一步操作无歧义，相同输入总产生相同输出；  
- **输入**：有零个或多个外部量作为输入；  
- **输出**：至少有一个量作为输出；  
- **可行性**：每一步均可通过基本操作在有限时间内完成（即“能行性”）。  

> 注：算法 ≠ 程序——程序可含无限循环（如操作系统），而算法必须终止。

---

### 2) 渐近表示：$O$、$\Omega$、$\Theta$ 记号的定义和相关性质及其证明  

#### 定义  
设 $f(n), g(n)$ 为定义在自然数集上的非负函数：  
- **大 $O$**（上界）：  
  $$
  f(n) = O(g(n)) \iff \exists c > 0,\, n_0 \in \mathbb{N},\, \forall n \ge n_0:\; 0 \le f(n) \le c\,g(n)
  $$  
- **大 $\Omega$**（下界）：  
  $$
  f(n) = \Omega(g(n)) \iff \exists c > 0,\, n_0 \in \mathbb{N},\, \forall n \ge n_0:\; 0 \le c\,g(n) \le f(n)
  $$  
- **大 $\Theta$**（紧确界）：  
  $$
  f(n) = \Theta(g(n)) \iff f(n) = O(g(n)) \text{ 且 } f(n) = \Omega(g(n))
  $$  
  等价于 $\exists c_1, c_2 > 0,\, n_0 \in \mathbb{N},\, \forall n \ge n_0:\; 0 \le c_1 g(n) \le f(n) \le c_2 g(n)$。

#### 相关性质  
- **传递性**：若 $f = O(g)$ 且 $g = O(h)$，则 $f = O(h)$；$\Omega, \Theta$ 同理；  
- **自反性**：$f = O(f)$, $f = \Omega(f)$, $f = \Theta(f)$；  
- **对称性**：$f = \Theta(g) \iff g = \Theta(f)$；  
- **转置对称性**：$f = O(g) \iff g = \Omega(f)$。

#### 示例证明（$2n^2 + 3n + 1 = \Theta(n^2)$）  
取 $c_1 = 2$, $c_2 = 6$, $n_0 = 1$：  
对 $\forall n \ge 1$，  
$$
2n^2 \le 2n^2 + 3n + 1 \le 2n^2 + 3n^2 + n^2 = 6n^2
$$  
故成立。

---

### 3) 什么是循环不变关系？用循环不变关系证明循环的正确性  

**循环不变关系**（Loop Invariant）是关于循环变量的一个谓词 $P$，满足：  
1. **初始化**（Initialization）：循环首次执行前 $P$ 成立；  
2. **保持**（Maintenance）：若第 $k$ 次迭代前 $P$ 成立，则第 $k+1$ 次迭代前 $P$ 仍成立；  
3. **终止**（Termination）：循环终止时 $P$ 与终止条件共同蕴含算法正确性。

#### 示例：插入排序外层循环  
```c
for (i = 1; i < n; ++i) {
    // 循环不变式 P: A[0..i-1] 已按非降序排列
}
```  
- **初始化**：$i=1$ 时 $A[0..0]$ 单元素，有序；  
- **保持**：插入 $A[i]$ 至正确位置，$A[0..i]$ 有序；  
- **终止**：$i = n$ 时 $A[0..n-1]$ 有序 ⇒ 正确。

---

### 4) 分治法的基本思想  
将原问题**分解**（Divide）为若干规模较小的子问题 → **递归求解**（Conquer）子问题 → **合并**（Combine）子问题的解得到原问题的解。  
典型三步：  
1. **分解**：将问题划分为 $a$ 个规模约为 $n/b$ 的子问题；  
2. **解决**：递归求解子问题；若子问题足够小则直接求解；  
3. **合并**：将子问题解组合为原问题解。

> 例：归并排序（$a=2, b=2$），合并需 $O(n)$；快速排序（$a=2$, $b$ 不定），合并 $O(1)$。

---

### 5) 以比较为基础的检索和分类算法的时间下界及其证明，熟练掌握其中几个典型算法  

#### 检索下界（有序表）  
- **决策树模型**：每次比较是二叉决策；  
- 查找 $n$ 元素中任一元素（成功/失败共 $2n+1$ 种结果）需决策树高度 $h \ge \log_2(2n+1) = \Omega(\log n)$；  
- 故**比较检索下界为 $\Omega(\log n)$**（二分查找达到此界）。

#### 排序下界  
- 对 $n!$ 种排列，决策树叶子数 $\ge n!$；  
- 高度 $h \ge \log_2(n!) = \Theta(n \log n)$（Stirling 公式：$\log n! \sim n\log n - n$）；  
- 故**比较排序下界为 $\Omega(n \log n)$**。

#### 典型算法  
| 算法 | 时间复杂度 | 是否最优 |  
|------|------------|----------|  
| 二分查找 | $O(\log n)$ | ✅ 达检索下界 |  
| 归并排序 | $O(n\log n)$ | ✅ 达排序下界 |  
| 堆排序 | $O(n\log n)$ | ✅ |  
| 快速排序（平均）| $O(n\log n)$ | ✅（期望意义）|

---

### 6) 为什么我们通常更关心算法的最坏情况执行时间？  
- **可预测性**：最坏情形给出**确定性上界**，便于系统资源规划（如实时系统 deadline 保证）；  
- **鲁棒性**：避免因输入“恶意构造”导致性能骤降（如快速排序退化为 $O(n^2)$）；  
- **理论分析简洁性**：相比平均/期望情形（需假设输入分布），最坏情形无需概率模型，更普适。

> 注：实际中若输入分布已知且稳定，可关注**平均情形**（如哈希）或**摊还分析**（如动态表）。

---

### 7) 用代换法、递归树法解递推式的基本思想  

#### 代换法（Substitution Method）  
1. **猜测**解的形式（如 $T(n) = O(n \log n)$）；  
2. **数学归纳法**证明：  
   - 基础情形验证；  
   - 假设 $T(k) \le c f(k)$ 对 $k < n$ 成立；  
   - 代入递推式，放缩得 $T(n) \le c f(n)$；  
3. 调整常数 $c$ 与 $n_0$ 使不等式成立。

#### 递归树法（Recursion Tree）  
- 将递推式展开为树：根为 $T(n)$，子结点为子问题代价；  
- 计算**每层代价** → 求和得总代价；  
- 适用于直观观察代价分布（尤其非齐次递推）；  
- 可辅助代换法“猜测”。

> 例：$T(n) = 2T(n/2) + n$  
> - 树高 $\log_2 n$，每层代价 $n$ ⇒ 总 $n \log n$。

---

### 8) 主方法及其使用  

对形如 $T(n) = a\,T\!\left(\frac{n}{b}\right) + f(n)$（$a \ge 1, b > 1$），定义 $n^{\log_b a}$ 为**临界函数**，比较 $f(n)$ 与之：

| 情况 | 条件 | 解 |
|------|------|-----|
| 1 | $f(n) = O\big(n^{\log_b a - \varepsilon}\big)$, $\varepsilon > 0$ | $T(n) = \Theta\big(n^{\log_b a}\big)$ |
| 2 | $f(n) = \Theta\big(n^{\log_b a} \log^k n\big)$, $k \ge 0$ | $T(n) = \Theta\big(n^{\log_b a} \log^{k+1} n\big)$ |
| 3 | $f(n) = \Omega\big(n^{\log_b a + \varepsilon}\big)$, $\varepsilon > 0$ 且 $a f(n/b) \le c f(n)$（正则条件） | $T(n) = \Theta\big(f(n)\big)$ |

> 例：  
> - $T(n)=4T(n/2)+n$：$n^{\log_2 4}=n^2$，$f(n)=n=O(n^{2-\varepsilon})$ ⇒ 情况1 ⇒ $T(n)=\Theta(n^2)$；  
> - $T(n)=2T(n/2)+n \log n$：$f(n)=\Theta(n^1 \log^1 n)$，$n^{\log_2 2}=n$ ⇒ 情况2（$k=1$） ⇒ $T(n)=\Theta(n \log^2 n)$。

---

### 10) 一个算法的平均情况运行时间和期望运行时间分别指什么？  

- **平均情况运行时间**：假设所有输入（通常指规模为 $n$ 的输入）**等概率出现**，计算运行时间的**算术平均值**；  
  $$
  T_{\text{avg}}(n) = \frac{1}{|\mathcal{I}_n|} \sum_{I \in \mathcal{I}_n} T(I)
  $$  
- **期望运行时间**：对输入集赋予**概率分布**（未必均匀），计算运行时间的**数学期望**：  
  $$
  \mathbb{E}[T(n)] = \sum_{I \in \mathcal{I}_n} \Pr[I] \cdot T(I)
  $$  

> 注：随机化算法中，即使输入固定，因内部随机性，期望时间仍非平凡（如随机快排期望 $O(n\log n)$）。

---

### 12) 了解期望时间和最坏情况时间是线性时间的选择算法的基本思想  

**BFPRT 算法**（又称 median-of-medians）：  
1. 将 $n$ 个元素分为 $\lceil n/5 \rceil$ 组，每组 5 元素；  
2. 对每组求中位数（共 $\lceil n/5 \rceil$ 个）；  
3. 递归调用本算法求这些中位数的中位数 $x$（即“中位数的中位数”）；  
4. 以 $x$ 为 pivot 分区；  
5. 递归求解含第 $k$ 小元素的子数组。

#### 关键性质  
- $x$ 至少比 $\frac{3n}{10} - 6$ 个元素大，至多比 $\frac{3n}{10} - 6$ 个小 ⇒ 子问题规模 $\le \frac{7n}{10} + 6$；  
- 递推式：$T(n) \le T(n/5) + T(7n/10 + 6) + O(n)$ ⇒ $T(n) = O(n)$（主方法变形/代换法可证）；  
- **最坏 $O(n)$**，但常数较大；实际多用**随机选择 pivot**（期望 $O(n)$，最坏 $O(n^2)$）。

---

### 13) 最优化问题是一类什么问题？  
最优化问题要求从**可行解集合**中找出使**目标函数**取**极值**（最大/最小）的解。形式化为：  
$$
\min_{\mathbf{x} \in \mathcal{F}} f(\mathbf{x}) \quad \text{或} \quad \max_{\mathbf{x} \in \mathcal{F}} f(\mathbf{x})
$$  
其中 $\mathcal{F}$ 为约束定义的可行域，$f$ 为目标函数。  
> 分类：线性/非线性、离散/连续、静态/动态、确定性/随机性等。

---

### 14) 什么是最优子结构性、无后效性？用剪切-粘贴法证明一个问题满足最优子结构性  

- **最优子结构**：问题的最优解包含其子问题的最优解；  
- **无后效性**：子问题的解一旦确定，后续决策不受其求解路径影响（即状态足以刻画历史）。

#### 剪切-粘贴法证明（以最短路径为例）  
**断言**：若 $p$ 是 $u \to v$ 的最短路径，$w$ 是 $p$ 上一点，则 $u \to w$ 段是 $u \to w$ 的最短路径。  
**证明**（反证）：  
- 假设存在更短路径 $p'$：$u \to w$ 长度 $< p$ 中 $u \to w$ 段；  
- 将 $p$ 中 $u \to w$ 段“剪切”，“粘贴” $p'$，得新路径 $u \xrightarrow{p'} w \rightsquigarrow v$；  
- 新路径长度 $< p$，与 $p$ 最短矛盾 ⇒ 原命题成立。

> 注：此方法广泛用于 DP 问题（如矩阵链乘、LCS）最优子结构证明。

---

### 15) 什么是状态转移方程？  
状态转移方程描述 DP 中**当前状态**如何由**先前状态**推导得出，是 DP 的核心递推公式。  
形式：  
$$
\text{dp}[i] = \min/\max/\sum \{ \text{dp}[j] + \text{cost}(j \to i) \mid j \in \text{predecessors}(i) \}
$$  

> 例：最长递增子序列（LIS）：  
> $$
> \text{dp}[i] = 1 + \max_{\substack{0 \le j < i \\ a[j] < a[i]}} \text{dp}[j]
> $$

---

### 16) 子问题图的画法  
- **结点**：每个子问题（常以状态参数表示，如 $(i,j)$）；  
- **有向边**：若求解子问题 $A$ 需先求子问题 $B$，则连边 $A \to B$（或反向，依定义）；  
- **拓扑序**：DP 计算顺序即子问题图的拓扑排序；  
- **环检测**：若图有环 ⇒ 无最优子结构或需重新定义状态。

> 例：矩阵链乘 $M[i,j]$ 依赖 $M[i,k], M[k+1,j]$，图呈三角 DAG。

---

### 17) 简述对动态规划所能带来计算性能改进的理解  

DP 通过**记忆化**（自顶向下）或**表格填表**（自底向上）避免重复计算子问题，将指数时间降为多项式时间。  

- **本质**：利用最优子结构 + 重叠子问题 ⇒ 将递归树转化为 DAG 上的路径计数；  
- **改进来源**：子问题总数 $= \text{状态数} = \text{多项式}$，而非 $O(\text{分支因子}^\text{深度})$；  
- **空间换时间**：典型时空权衡（如 Fibonacci 从 $O(2^n)$ → $O(n)$ 时间 + $O(n)$ 空间）。

> 关键：状态设计决定复杂度——好的状态压缩可大幅优化（如 Bitmask DP、滚动数组）。

---

### 18) 贪心算法的基本思想和一般步骤。什么是贪心选择性和贪心选择？  

#### 基本思想  
每步做出**局部最优选择**（贪心选择），期望导致全局最优解。

#### 一般步骤  
1. 将问题分解为若干阶段；  
2. 定义**贪心策略**（如选最大/最小/最早结束等）；  
3. 证明**贪心选择性**与**最优子结构**；  
4. 迭代/递归构造解。

#### 贪心选择性  
问题的**全局最优解**可通过**一次贪心选择** + **剩余子问题的最优解**构成。

#### 贪心选择  
每步依据贪心策略选出的局部最优决策（如活动选择中选**最早结束**活动）。

> 成功关键：贪心选择性成立 ⇒ 无需回溯/枚举。

---

### 19) 比较动态规划和贪心方法的异同  

| 特性 | 动态规划 | 贪心算法 |
|------|----------|----------|
| **子问题重叠** | ✅ 必需 | ❌ 通常无 |
| **最优子结构** | ✅ 必需 | ✅ 必需 |
| **贪心选择性** | ❌ 无需 | ✅ 必需 |
| **求解方式** | 自底向上 / 记忆化递归 | 自顶向下，单路径构造 |
| **时间复杂度** | 多项式（常较高） | 多项式（常更低） |
| **正确性证明** | 数学归纳 / 剪切粘贴 | 贪心选择性 + 最优子结构 |
| **典型问题** | 背包、LCS、矩阵链 | 活动选择、Huffman、MST |

> 同：均依赖最优子结构；  
> 异：DP 存储所有子问题解，贪心只保留当前最优路径。

---

### 20) 什么叫切割、横断切割、轻量级边、安全边？  

- **切割**（Cut）：对顶点集 $V$ 划分为 $S$ 与 $V \setminus S$（$S \ne \varnothing, V$）；  
- **横断边**（Crossing Edge）：一端在 $S$、另一端在 $V \setminus S$ 的边；  
- **轻量级边**（Light Edge）：横断边中**权重最小**者（可不唯一）；  
- **安全边**（Safe Edge）：加入当前森林 $A$ 后仍为某 MST 子集的边。

> **关键定理**（MST 安全边）：任一不破坏森林的切割中，其轻量级边是安全边。

---

### 21) 了解Kruskal和Prim算法的贪心思想和算法过程  

| 算法 | 贪心策略 | 过程简述 |
|------|----------|----------|
| **Kruskal** | 每次选**全局最小权重**且不构成环的边 | 1. 边按权升序排序；<br>2. 依次取边，若两端不在同一连通分量（并查集维护），加入 MST； |
| **Prim** | 从任一点出发，每次选连接**当前树与外部点**的最小边 | 1. 初始化 $A = \{v_0\}$；<br>2. 维护优先队列（key=到 $A$ 最短距离）；<br>3. 提取最小 key 点 $u$，加入 $A$，松弛其邻边； |

> 时间：Kruskal $O(E \log E)$；Prim（二叉堆）$O(E \log V)$，（斐波那契堆）$O(E + V \log V)$。

---

### 22) 什么是松弛操作？  
对边 $(u, v)$ 的**松弛**（Relaxation）是尝试改进 $v$ 的最短路径估计 $d[v]$：  
```python
if d[v] > d[u] + w(u, v):
    d[v] = d[u] + w(u, v)
    π[v] = u   # 更新前驱
```  
——即用经 $u$ 的路径更新 $v$ 的距离上界。

> 所有单源最短路径算法（Dijkstra, BF, SPFA）的核心操作。

---

### 23) 最短路和松弛操作的相关性质  

- **三角不等式**：$\delta(s, v) \le \delta(s, u) + w(u, v)$；  
- **上界性质**：$d[v] \ge \delta(s, v)$ 恒成立（若初始化 $d[s]=0, d[v]=\infty$）；  
- **非路径性质**：若 $v$ 不可达，则 $d[v] = \infty = \delta(s, v)$；  
- **收敛性质**：若 $s \leadsto u \to v$ 是最短路径，且 $d[u] = \delta(s, u)$，则松弛 $(u,v)$ 后 $d[v] = \delta(s, v)$；  
- **路径松弛性质**：若 $p = \langle v_0=s, v_1, \dots, v_k=v \rangle$ 是最短路径，按序松弛 $p$ 上所有边，则 $d[v] = \delta(s, v)$（即使中间有其他操作）。

---

### 24) 举例说明在带有负权重边的图上Dijkstra算法工作异常  

**反例图**：$V = \{A, B, C\}$，边：$A \xrightarrow{1} B$，$A \xrightarrow{4} C$，$B \xrightarrow{-3} C$。  
- 实际最短路：$A \to B \to C$，长 $1 + (-3) = -2$；  
- Dijkstra 步骤：  
  1. $A$ 出队，更新 $B(d=1), C(d=4)$；  
  2. $B$ 出队（当前最小 $d=1$），松弛得 $C$ 新 $d = 1 - 3 = -2$；  
  3. 但 **$C$ 已标记永久**（Dijkstra 认为 $d=4$ 最优），不再更新 ⇒ 输出 $d[C]=4$，错误！

> 根本原因：Dijkstra 假设边权非负 ⇒ 一旦结点出队，$d[v]$ 即为最终值；负权边破坏此假设。

---

### 25) Bellman-Ford算法是如何检查图中可能存在的负权重回路的？  

算法执行 $|V| - 1$ 轮松弛（保证无负环时收敛），再进行**第 $|V|$ 轮松弛检测**：  
- 若存在边 $(u, v)$ 使得 $d[v] > d[u] + w(u, v)$，则说明 $v$ 可被进一步松弛 ⇒  
  $v$ 可达负权环 ⇒ 图含**从源点可达的负权环**。

> 原理：无负环时，最短路径至多 $|V|-1$ 边；第 $|V|$ 次仍可松弛 ⇒ 必含环且总权为负。

---

### 26) 了解Johnson算法对图权值改造的基本思想  

为使 Dijkstra 可用于负权图（但无负环），Johnson 算法通过**势函数重赋权**：  
1. 添加新源点 $s$，连向所有 $v \in V$，边权 0；  
2. 运行 Bellman-Ford 得 $h(v) = \delta(s, v)$；  
3. 定义新权重：  
   $$
   \hat{w}(u, v) = w(u, v) + h(u) - h(v)
   $$  
4. 对每个 $u$，以 $\hat{w}$ 运行 Dijkstra 求 $\hat{\delta}(u, v)$；  
5. 还原真实距离：$\delta(u, v) = \hat{\delta}(u, v) - h(u) + h(v)$。

> 性质：$\hat{w} \ge 0$（由三角不等式保证），且路径相对长短不变。

---

### 27) 了解BFS、DFS、D-Search的异同  

| 算法 | 数据结构 | 用途 | 性质 |
|------|----------|------|------|
| **BFS** | 队列 | 无权最短路径、连通分量、层次遍历 | 按层扩展，首次访问即最短路径 |
| **DFS** | 栈（递归/显式） | 拓扑排序、强连通分量、桥/割点、路径枚举 | 深入探索，用发现/完成时间（$d, f$）刻画结构 |
| **D-Search**（深度优先搜索的统称） | 同 DFS | 同 DFS | 有时特指带回溯的搜索（如解空间树） |

> 共性：均生成生成树/森林；均可检测环；时间 $O(V + E)$。

---

### 28) 生成树：宽度优先生成树、深度优先生成树、最小成本生成树、单源点最短路径生成树  

| 类型 | 生成方式 | 核心性质 |
|------|----------|----------|
| **BFS 生成树** | BFS 遍历时记录父边 | 树高 = 源点偏心率；$s$ 到 $v$ 路径是图中**边数最短**路径 |
| **DFS 生成树** | DFS 遍历时记录父边 | 含前向边、后向边、横跨边；后向边 ⇔ 环 |
| **MST** | Kruskal / Prim | 总权最小；无环连通；满足切割性质 |
| **SPT**（Shortest Path Tree） | Dijkstra / BF | $s$ 到 $v$ 树上路径 = 图中最短路径（权值和最小） |

> 注意：MST 与 SPT 一般不同（除非边权满足特殊条件）。

---

### 29) 什么是回溯法、分支-限界法？限界函数的作用是什么？  

- **回溯法**：DFS 遍历**解空间树**，用**约束函数**剪去不满足约束的子树，**仍遍历可行解**；  
- **分支-限界法**：BFS（或优先队列）遍历解空间树，用**限界函数**剪去**不可能优于当前最优解**的子树；

#### 限界函数作用  
- 提供子树中**最优解上界**（最大化问题）或**下界**（最小化问题）；  
- 若限界值劣于当前最优 ⇒ 整棵子树剪枝；  
- 显著减少搜索结点（如 0-1 背包用分数背包界）。

> 实现：LC-检索（Least Cost）中，优先队列按 $ \hat{C}(X) = g(X) + h(X) $ 排序。

---

### 30) 有关状态空间、解空间、状态空间树及检索和周游的基本概念  

- **状态空间**：问题求解过程中所有可能状态的集合；  
- **解空间**：状态空间中满足目标条件的状态子集；  
- **状态空间树**：根为初始状态，结点为状态，边为操作；叶结点为解或死端；  
- **检索**（Search）：在树中找解结点（可用约束/限界剪枝）；  
- **周游**（Traversal）：系统访问所有结点（如 DFS/BFS 遍历）。

> 应用：N-皇后（解空间是 $n!$ 排列子集），0-1 背包（$2^n$ 子集）。

---

### 31) 简述LC检索的基本思想  

**LC 检索**（Least Cost Branch and Bound）：  
- 用**活结点表**（优先队列）存储待扩展结点；  
- 优先级由**估计成本函数** $\hat{C}(X)$ 决定（越小越优先）；  
- $\hat{C}(X) = g(X) + h(X)$：  
  - $g(X)$：从根到 $X$ 的实际成本；  
  - $h(X)$：从 $X$ 到目标的**启发式估计成本**（需满足 $h(X) \le h^*(X)$ 才保最优）；  
- 每次扩展 $\hat{C}$ 最小的活结点，直至找到解。

> 注：若 $h(X) \equiv 0$，退化为 FIFO 分支限界；$h$ 为最优估计时即 A* 算法。

---

### 32) 什么是结点成本函数和结点成本估计函数？结点成本估计函数 $\hat{C}(X)$ 中 $h$ 函数和 $g$ 函数分别对算法带来什么影响？  

- **结点成本函数** $C(X)$：从根经 $X$ 到达目标解的**最小实际成本**（未知，待求）；  
- **结点成本估计函数** $\hat{C}(X)$：$C(X)$ 的**可计算估计**，用于指导搜索。

#### $g(X)$ 与 $h(X)$ 的影响  
- $g(X)$：**已付出代价**，确保路径真实性；过大会倾向浅层结点；  
- $h(X)$：**未来代价启发**，决定搜索方向；  
  - $h(X)$ **越精确** ⇒ 搜索效率越高；  
  - $h(X) \le h^*(X)$（可接纳） ⇒ 保证找到最优解；  
  - $h(X)$ 大但可接纳 ⇒ 更快收敛（如曼哈顿距离 vs 欧氏距离 in A*）。

> 权衡：$h$ 计算越复杂，单步耗时增，但扩展结点少。

---

### 33) 了解 $h^*$ 函数的性质，了解 $C(X)$ 上界的作用  

- $h^*(X)$：从状态 $X$ 到目标的**真实最小成本**；  
- **性质**：  
  - $h^*(X) = 0$ 当且仅当 $X$ 是目标；  
  - 满足三角不等式：$h^*(X) \le w(X, Y) + h^*(Y)$；  
- **$C(X)$ 上界 $U$ 的作用**：  
  - 在分支限界中，若 $\hat{C}(X) \ge U$ ⇒ 结点 $X$ 可剪枝；  
  - 初始 $U$ 可由贪心/随机算法得可行解；  
  - 搜索中 $U$ 动态更新（遇更优解则缩小），剪枝能力增强。

---

### 34) 什么是流网络、最大流？  

- **流网络** $G = (V, E)$：有向图，含源点 $s$、汇点 $t$，每边 $(u,v)$ 有权重 $c(u,v) \ge 0$（容量）；  
- **流** $f$：满足：  
  1. **容量约束**：$0 \le f(u,v) \le c(u,v)$；  
  2. **流量守恒**：$\forall u \ne s,t,\ \sum_v f(v,u) = \sum_v f(u,v)$；  
- **流值** $|f| = \sum_v f(s,v) - \sum_v f(v,s)$；  
- **最大流**：所有可行流中**流值最大者**。

---

### 35) Ford-Fulkerson方法：残存网络、增广路径、最大流最小切割定理  

- **残存网络** $G_f = (V, E_f)$：  
  - 边集含：  
    - 若 $f(u,v) < c(u,v)$，加前向边 $(u,v)$，残存容量 $c_f(u,v) = c(u,v) - f(u,v)$；  
    - 若 $f(u,v) > 0$，加反向边 $(v,u)$，残存容量 $c_f(v,u) = f(u,v)$；  
- **增广路径** $p$：$G_f$ 中 $s \leadsto t$ 的路径；  
  - 可增广流量 $\Delta = \min_{(u,v) \in p} c_f(u,v)$；  
- **Ford-Fulkerson 方法**：  
  1. 初始化 $f = 0$；  
  2. 在 $G_f$ 中找增广路径 $p$；  
  3. 若存在，沿 $p$ 增广 $\Delta f$；重复；否则终止。  

#### 最大流最小切割定理  
$$
\max |f| = \min_{(S, T): s \in S, t \in T} c(S, T)
$$  
其中 $c(S, T) = \sum_{u \in S, v \in T} c(u, v)$ 为切割容量。

> 注：Edmonds-Karp（BFS 找最短增广路）确保 $O(VE^2)$。

---

## 三、算法部分  

### 1. 算法设计的基本策略  

#### 1) 增量式算法设计策略  
**思想**：从空解或平凡解出发，**逐次添加一个元素**，并维护当前解的正确性/最优性。  
**典型算法**：插入排序、Dijkstra 算法（增量加入最短路径确定点）、Prim 算法（增量加入 MST 点）。  
**特点**：  
- 实现简单，易理解；  
- 通常需维护“已处理部分”的某种不变量（如插入排序的前 $i$ 个元素有序）；  
- 时间复杂度常为 $O(n^2)$（若每次插入需线性扫描）。  

---

#### 2) 分治策略  
**思想**：分解（Divide）→ 解决（Conquer）→ 合并（Combine）。  
**关键要求**：  
- 子问题**独立**（无重叠）；  
- 合并代价可控。  
**典型算法**：归并排序、快速排序、Strassen 矩阵乘、最近点对。  
**时间分析**：主方法适用。  

> 注：与动态规划区别——分治子问题**不重叠**，DP 子问题**高度重叠**。

---

#### 3) 贪心策略  
**思想**：每步做**当前局部最优选择**，期望导出全局最优。  
**正确性条件**：  
- **贪心选择性**：全局最优解包含某贪心选择；  
- **最优子结构**：选择后剩余子问题最优 ⇒ 原问题最优。  
**典型算法**：活动选择、Huffman 编码、MST（Prim/Kruskal）、Dijkstra。  
**优势**：通常高效（$O(n \log n)$ 或 $O(n)$）；**风险**：易错，需严格证明。

---

#### 4) 动态规划  
**思想**：利用**最优子结构** + **重叠子问题**，通过**填表**避免重复计算。  
**两种实现方式**：  
- **自顶向下**（记忆化递归）：按需计算 + 缓存；  
- **自底向上**（填表）：按拓扑序递推，空间可优化（如滚动数组）。  
**设计步骤**：  
1. 刻画最优解结构；  
2. 递归定义最优值；  
3. 计算最优值（填表）；  
4. 构造最优解（可选）。  
**典型问题**：钢条切割、LCS、0-1 背包、矩阵链乘。

---

#### 5) 宽度优先搜索（BFS）  
**思想**：按**层序**扩展，用**队列**实现；首次访问即为最小步数/最短路径（无权图）。  
**应用**：  
- 无权图单源最短路径；  
- 连通分量、二分图检测；  
- 分支限界（FIFO 式）。  
**时间**：$O(V + E)$；**空间**：$O(V)$（队列最坏存一层所有点）。

---

#### 6) 深度优先搜索（DFS）  
**思想**：尽可能深地探索分支，用**栈**（递归/显式）实现；记录发现时间 $d[u]$ 和完成时间 $f[u]$。  
**应用**：  
- 拓扑排序（DAG）；  
- 强连通分量（Kosaraju/Tarjan）；  
- 桥/割点检测；  
- 回溯法基础。  
**时间**：$O(V + E)$；**空间**：$O(V)$（递归栈深度）。

---

### 2. 算法问题和算法  

#### 1) 排序算法  

| 算法 | 思想 | 时间 | 空间 | 稳定？ | 原地？ | 适用场景 |
|------|------|------|------|--------|--------|----------|
| **插入排序** | 增量插入，维护前 $i$ 元素有序 | 最坏/平均 $O(n^2)$，最好 $O(n)$ | $O(1)$ | ✅ | ✅ | 小规模/近有序 |
| **归并排序** | 分治：排序左右 + 合并 | $O(n \log n)$（全情形） | $O(n)$ | ✅ | ❌ | 稳定排序需求 |
| **快速排序** | 分治：选 pivot 分区 + 递归 | 平均 $O(n \log n)$，最坏 $O(n^2)$ | $O(\log n)$（栈） | ❌ | ✅ | 通用，cache 友好 |
| **堆排序** | 建最大堆 + 重复 extract-max | $O(n \log n)$ | $O(1)$ | ❌ | ✅ | 原地 $O(n \log n)$ |
| **计数排序** | 桶统计 + 前缀和定位 | $O(n + k)$（$k$=值域） | $O(k)$ | ✅ | ❌ | 小整数、$k = O(n)$ |

> 注：快排优化：三数取中、小数组转插入排序、尾递归优化。

---

#### 2) 分治相关  

| 问题 | 算法 | 思想 | 时间 |
|------|------|------|------|
| **最大子数组** | 分治 | 跨中点最大子数组 = max(左最大, 右最大, 左尾+右首) | $T(n)=2T(n/2)+O(n) \Rightarrow O(n \log n)$<br>（Kadane 算法可 $O(n)$） |
| **Strassen 矩阵乘** | 分治 | 将 $n \times n$ 分为 $4$ 个 $n/2$ 块，用 7 次乘法代替 8 次 | $T(n)=7T(n/2)+O(n^2) \Rightarrow O(n^{\log_2 7}) \approx O(n^{2.81})$ |
| **最近点对** | 分治 | 按 $x$ 排序分左右；合并时仅检查中线两侧 $\delta$ 宽条带内点（每点至多比 7 个） | $T(n)=2T(n/2)+O(n) \Rightarrow O(n \log n)$ |
| **期望线性选择** | 随机快排变种 | 随机选 pivot，期望子问题规模 $\le 3n/4$ | $\mathbb{E}[T(n)] = O(n)$ |
| **最坏线性选择** | BFPRT | 5-分组取中位数的中位数为 pivot，保证子问题 $\le 7n/10 + 6$ | $T(n) \le T(n/5) + T(7n/10 + 6) + O(n) \Rightarrow O(n)$ |

---

#### 4) 查找问题  

| 问题 | 算法 | 思想 | 时间 |
|------|------|------|------|
| **二分查找** | 减治 | 比较中点，舍弃一半 | $O(\log n)$ |
| **找最大最小** | 分治 | 成对比较：$\lfloor n/2 \rfloor$ 次比较得 $\lfloor n/2 \rfloor$ 胜者/败者，再分别找最大/最小 | $ \lceil 3n/2 \rceil - 2 $ 次比较（最优） |
| **找最大次大** | 锦标赛法 | 构造淘汰树：最大值路径上有 $\lceil \log_2 n \rceil$ 个“输给最大值”的元素，从中取最大即次大 | $ n + \lceil \log_2 n \rceil - 2 $ 次比较（最优） |

---

#### 6) 动态规划相关  

| 问题 | 状态定义 | 状态转移 | 时间/空间 |
|------|----------|----------|-----------|
| **钢条切割** | $r[i]$：长为 $i$ 钢条最大收益 | $r[i] = \max_{1 \le j \le i} (p_j + r[i-j])$<br>或 $r[i] = \max(p_i, \max_{1 \le j < i} (r[j] + r[i-j]))$ | $O(n^2)$/ $O(n)$ |
| **矩阵链乘** | $m[i,j]$：$A_i \cdots A_j$ 最小标量乘次数 | $m[i,j] = \min_{i \le k < j} \{ m[i,k] + m[k+1,j] + p_{i-1}p_k p_j \}$ | $O(n^3)$/ $O(n^2)$ |
| **LCS** | $c[i,j]$：$X[1..i], Y[1..j]$ 的 LCS 长 | $c[i,j] = \begin{cases} 0 & i=0 \text{ or } j=0 \\ c[i-1,j-1]+1 & x_i=y_j \\ \max(c[i-1,j], c[i,j-1]) & \text{else} \end{cases}$ | $O(mn)$/ $O(mn)$（可滚动数组 $O(\min(m,n))$） |
| **最优 BST** | $e[i,j]$：含 $k_i..k_j$ 且 dummy $d_{i-1}..d_j$ 的子树期望搜索代价 | $e[i,j] = \min_{i \le r \le j} \{ e[i,r-1] + e[r+1,j] + w(i,j) \}$<br>$w(i,j) = w(i,j-1) + p_j + q_j$ | $O(n^3)$/ $O(n^2)$ |
| **0-1 背包** | $dp[i,w]$：前 $i$ 物品、容量 $w$ 的最大价值 | $dp[i,w] = \max(dp[i-1,w],\; dp[i-1,w-w_i] + v_i)$ | $O(nW)$/ $O(nW)$（可滚动 $O(W)$） |
| **Bellman-Ford** | $d_k[v]$：最多 $k$ 条边的最短路径估计 | $d_k[v] = \min \{ d_{k-1}[v],\; \min_{(u,v)\in E} (d_{k-1}[u] + w(u,v)) \}$ | $O(VE)$ |
| **Floyd-Warshall** | $D^{(k)}[i,j]$：中间点 $\subseteq \{1..k\}$ 的最短路 | $D^{(k)}[i,j] = \min(D^{(k-1)}[i,j],\; D^{(k-1)}[i,k] + D^{(k-1)}[k,j])$ | $O(V^3)$/ $O(V^2)$ |

> 注：BF 与 Floyd 均可检测负环；Floyd 还可重构路径（用 $\pi^{(k)}[i,j]$）。

---

#### 7) 贪心策略相关  

| 问题 | 贪心策略 | 正确性依据 | 时间 |
|------|----------|------------|------|
| **活动选择** | 选**最早结束时间**的兼容活动 | 贪心选择性：存在最优解包含最早结束活动 | $O(n \log n)$（排序） |
| **分数背包** | 按单位价值 $v_i/w_i$ 降序取 | 局部最优 ⇒ 全局最优（可分性） | $O(n \log n)$ |
| **Huffman 编码** | 反复合并**频率最小**两棵树 | 贪心选择性：最小频字符必在最深；最优子结构 | $O(n \log n)$（优先队列） |
| **最优归并** | 反复合并**最小两个文件** | 同 Huffman（归并代价 = 文件大小和） | $O(n \log n)$ |
| **MST** | 见下节 | 切割性质 ⇒ 轻边安全 | — |
| **Dijkstra** | 选 $d[u]$ 最小的未确定点 | 边权 $\ge 0$ 时，$d[u]$ 即最短距离 | $O(V^2)$ 或 $O(E \log V)$ |

> 注：0-1 背包**不能**贪心（除非特殊条件）。

---

#### 8) 最小生成树  

| 概念/算法 | 内容 |
|-----------|------|
| **MST 性质** | - 切割性质：轻边安全<br>- 环性质：环上最大边非 MST 边 |
| **贪心策略** | 每步加一条**安全边**（不构成环 + 横断轻边） |
| **Prim 算法** | 类 Dijkstra：<br>1. $A = \{r\}$；2. 维护 min-heap（key = 到 $A$ 最短边权）；<br>3. 提取 min，加边 $(u,v)$，松弛 $v$ 邻边 | $O(E \log V)$ |
| **Kruskal 算法** | 1. 边按权升序；2. 并查集维护连通性；3. 依次加不构成环的边 | $O(E \log E)$ |

> 对比：Prim 适合稠密图；Kruskal 适合稀疏图 + 易并行。

---

#### 9) 最短路相关  

| 问题 | 算法 | 适用条件 | 时间 | 扩展 |
|------|------|----------|------|------|
| **单源最短路** | **Bellman-Ford** | 无负环（可检测） | $O(VE)$ | 差分约束：$x_j - x_i \le b_k \Leftrightarrow (i,j)$ 边权 $b_k$，求 $x_i \le x_0 + d[i]$ |
|  | **Dijkstra** | 边权 $\ge 0$ | $O(E \log V)$ | — |
| **全源最短路** | **Floyd-Warshall** | 无负环（可检测） | $O(V^3)$ | 传递闭包（$D^{(k)}[i,j] = D^{(k-1)}[i,j] \lor (D^{(k-1)}[i,k] \land D^{(k-1)}[k,j])$） |
|  | **Johnson** | 无负环 | $O(VE \log V)$ | 重赋权后对每点 Dijkstra |

> **差分约束系统求解**：  
> - 构图：每个变量 $x_i$ 为点，约束 $x_j - x_i \le b$ 为边 $(i,j)$ 权 $b$；  
> - 加超级源 $s$ 连所有点（权 0）；  
> - BF 求 $d[i]$，则 $x_i = d[i]$ 是一组解。

---

#### 10) 深度优先搜索（回溯法）  

| 问题 | 解空间树 | 关键优化 |
|------|----------|----------|
| **n-皇后** | 排列树（$n!$ 叶） | - 行唯一（排列）<br>- 列/对角线约束：用 $col$, $diag1$, $diag2$ 位掩码或布尔数组 |
| **子集和数** | 子集树（$2^n$ 叶） | - 限界：当前和 + 剩余和 $<$ target ⇒ 剪枝<br>- 约束：当前和 $>$ target ⇒ 剪枝 |

> **回溯框架**：  
> ```python
> def backtrack(path, choice_list):
>     if 满足结束条件: result.append(path.copy()); return
>     for choice in choice_list:
>         if 约束(choice): continue
>         path.append(choice)
>         backtrack(path, new_choice_list)
>         path.pop()  # 回溯
> ```

---

#### 11) 宽度优先搜索（分支限界 / A*）  

| 问题 | 算法 | 核心思想 |
|------|------|----------|
| **分支限界** | FIFO / LIFO / LC | 用队列/栈/优先队列管理活结点；限界函数剪枝 |
| **A* 算法** | LC 分支限界特例 | $\hat{C}(X) = g(X) + h(X)$，$h$ 可接纳 ⇒ 最优；$h$ 一致 ⇒ 高效 |
| **带限期作业排序** | 分支限界 | 状态 $X$：已调度作业子集 + 时间；<br>限界：贪心得上界；约束：时间 $\le$ 期限 |

> **作业排序限界函数**：  
> - 贪心调度剩余作业（按 deadline 升序），得最大收益 $U$；  
> - 若当前收益 + $U \le$ 最优已知 ⇒ 剪枝。

---

#### 12) 网络流  

| 概念/算法 | 内容 |
|-----------|------|
| **流网络** | $G=(V,E)$，$s,t \in V$，$c(u,v) \ge 0$；流 $f$ 满足容量约束 & 流量守恒 |
| **最大流** | $\max |f| = \sum_v f(s,v) - \sum_v f(v,s)$ |
| **Ford-Fulkerson** | 1. $f=0$；2. 在 $G_f$ 中找增广路 $p$；3. 增广 $\Delta = \min c_f(p)$；<br>**问题**：若容量无理数，可能不终止；整数容量 ⇒ $O(|f^*| \cdot E)$ |
| **Edmonds-Karp** | FF + **BFS 找最短增广路**（边数最少） | $O(VE^2)$；每条边至多成为关键边 $O(V)$ 次 |

> **关键引理**：  
> - 若用 BFS，则 $s$ 到任点的最短距离 $d_f(v)$ 随增广**单调不减**；  
> - 边 $(u,v)$ 为关键边 ⇒ $d_f(v) = d_f(u) + 1$，且下次出现时 $d_f(v) \ge d_f(u) + 1 + 2$ ⇒ 每点 $O(V)$ 次。