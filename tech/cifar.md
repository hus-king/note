# é’ˆå¯¹32å¼ å·²çŸ¥ CIFAR-100 å›¾åƒçš„åˆ†ç±»æ¨¡å‹è®­ç»ƒä¸æ¨ç†æŒ‡å—

æœ¬æ–‡æ¡£åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š**è®­ç»ƒè„šæœ¬**å’Œ**æ¨ç†è„šæœ¬**ã€‚  
æˆ‘ä»¬ä½¿ç”¨ **ResNet-18** æ„å»ºä¸€ä¸ªé’ˆå¯¹ 16 ç±»ã€å…± 32 å¼ å›¾åƒçš„å°æ ·æœ¬åˆ†ç±»æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚

---

## ğŸ§  æ¨¡å‹è®­ç»ƒ

### æ–‡ä»¶ç»“æ„è¦æ±‚

è¯·ç¡®ä¿ä½ çš„æ•°æ®é›†ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
./dataset/
    â”œâ”€â”€ class1/
    â”‚   â”œâ”€â”€ img1.png
    â”‚   â””â”€â”€ img2.png
    â”œâ”€â”€ class2/
    â”‚   â”œâ”€â”€ img1.png
    â”‚   â””â”€â”€ img2.png
    ...
    â””â”€â”€ class16/
        â”œâ”€â”€ img1.png
        â””â”€â”€ img2.png
```

æ¯ä¸ªç±»åˆ«ä¸‹æœ‰ 2 å¼ å›¾ç‰‡ï¼Œæ€»å…± 32 å¼ å›¾åƒã€‚

### è®­ç»ƒæµç¨‹è¯´æ˜

- ä½¿ç”¨ `CustomImageDataset` è‡ªå®šä¹‰åŠ è½½å™¨è¯»å–æ•°æ®ï¼›
- åº”ç”¨åŸºæœ¬çš„é¢„å¤„ç†ï¼ˆResize åˆ° 224x224 å¹¶è½¬ä¸º Tensorï¼‰ï¼›
- åŠ è½½é¢„è®­ç»ƒ ResNet-18 æ¨¡å‹ï¼Œå¹¶å°†æœ€åçš„å…¨è¿æ¥å±‚æ›¿æ¢ä¸ºé€‚ç”¨äº 16 ç±»è¾“å‡ºçš„çº¿æ€§å±‚ï¼›
- å†»ç»“ä¸»å¹²ç½‘ç»œå‚æ•°ï¼Œä»…è®­ç»ƒæœ€åä¸€å±‚ï¼›
- ä½¿ç”¨ Adam ä¼˜åŒ–å™¨è¿›è¡Œå¾®è°ƒï¼›
- è¿›è¡Œ 50 è½®è®­ç»ƒåä¿å­˜æ¨¡å‹æƒé‡ï¼›
- æœ€ååœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œæµ‹è¯•å¹¶è¾“å‡ºé¢„æµ‹ç»“æœã€‚

### âœ… è®­ç»ƒä»£ç 

```python
import os
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader

# è‡ªå®šä¹‰æ•°æ®é›†
class CustomImageDataset(Dataset):
    def __init__(self, root, transform=None):
        self.root = root
        self.transform = transform
        self.classes = sorted(os.listdir(root))
        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}
        self.samples = [
            (os.path.join(root, c, f), self.class_to_idx[c])
            for c in self.classes for f in os.listdir(os.path.join(root, c))
        ]

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        image = Image.open(path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label


# æ•°æ®å¢å¼ºä¸åŠ è½½
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

dataset = CustomImageDataset(root='./dataset', transform=transform)
loader = DataLoader(dataset, batch_size=4, shuffle=True)

# æ¨¡å‹æ„å»º
model = models.resnet18(weights="IMAGENET1K_V1")
model.fc = nn.Linear(512, len(dataset.classes))
model = model.cuda()

# å†»ç»“ä¸»å¹²ç½‘ç»œ
for param in model.parameters():
    param.requires_grad = False
model.fc.requires_grad_(True)

# è®­ç»ƒé…ç½®
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)

# è®­ç»ƒå¾ªç¯
model.train()
for epoch in range(50):
    for images, labels in loader:
        images, labels = images.cuda(), labels.cuda()
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
# è®­ç»ƒç»“æŸåä¿å­˜æ¨¡å‹
torch.save(model.state_dict(), "resnet18_custom.pth")
print("Model saved to resnet18_custom.pth")

# æµ‹è¯•
model.eval()
with torch.no_grad():
    for images, labels in loader:
        images, labels = images.cuda(), labels.cuda()
        outputs = model(images)
        predicted = torch.argmax(outputs, dim=1)
        print("Labels:", labels)
        print("Predicted:", predicted)
```

---

## ğŸ” æ¨¡å‹æ¨ç†

æ¨ç†è„šæœ¬ç”¨äºå¯¹æµ‹è¯•æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒè¿›è¡Œåˆ†ç±»é¢„æµ‹ã€‚

### æ–‡ä»¶ç»“æ„è¦æ±‚

è¯·ç¡®ä¿ä½ çš„æµ‹è¯•å›¾åƒå­˜æ”¾åœ¨å¦‚ä¸‹è·¯å¾„ä¸­ï¼š

```
./test/
    â”œâ”€â”€ test1.png
    â”œâ”€â”€ test2.png
    â””â”€â”€ ...
```

è¿™äº›å›¾åƒåº”ä¸ºè®­ç»ƒæ—¶ä½¿ç”¨çš„ç›¸åŒ 32 å¼ å›¾åƒã€‚

### æ¨ç†æµç¨‹è¯´æ˜

- é‡æ–°æ„é€ ä¸è®­ç»ƒä¸€è‡´çš„ ResNet-18 ç½‘ç»œç»“æ„ï¼›
- åŠ è½½ä¹‹å‰è®­ç»ƒä¿å­˜çš„æ¨¡å‹æƒé‡ï¼›
- ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†ï¼›
- å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†å¹¶é¢„æµ‹å…¶æ‰€å±ç±»åˆ«ï¼›
- è¾“å‡ºå›¾åƒåç§°åŠå¯¹åº”çš„é¢„æµ‹ç±»åˆ«åç§°ã€‚

### âœ… æ¨ç†ä»£ç 

```python
import torch
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image
import os

# ç±»åˆ«æ•°é‡ï¼ˆæ ¹æ®ä½ çš„æ•°æ®é›†è°ƒæ•´ï¼‰
num_classes = 16  # ä¸æƒé‡æ–‡ä»¶ä¿æŒä¸€è‡´

# åŠ è½½æ¨¡å‹ç»“æ„
model = models.resnet18(weights=None)
model.fc = torch.nn.Linear(512, num_classes)

# åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
model.load_state_dict(torch.load("resnet18_custom.pth", map_location=torch.device('cpu')))
model = model.cpu()  # ä½¿ç”¨ CPU
model.eval()

# å›¾åƒé¢„å¤„ç†ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ç±»åˆ«ç´¢å¼•åˆ°ç±»åˆ«åç§°çš„æ˜ å°„
class_names = [
    "camel",
    "chair",
    "dolphin",
    "hamster",
    "lion",
    "maple_tree",
    "orange",
    "orchid",
    "pickup_truck",
    "pine",
    "rabbit",
    "skyscraper",
    "squirrel",
    "tractor",
    "turtle",
    "willow_tree"
]

# æ¨ç†å‡½æ•°
def predict_image(image_path):
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0)  # ä¸å†ç§»åˆ° GPU
    with torch.no_grad():
        output = model(image)
        predicted_idx = torch.argmax(output, dim=1).item()
    return predicted_idx

# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    test_dir = "./test"
    for fname in os.listdir(test_dir):
        if fname.lower().endswith(".png"):
            image_path = os.path.join(test_dir, fname)
            predicted_class = predict_image(image_path)
            print(f"{fname}: {class_names[predicted_class]}")
```

---

## ğŸ“Œ æ€»ç»“

è¯¥æ–‡æ¡£æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒä¸æ¨ç†æµç¨‹ï¼Œé€‚ç”¨äºå°æ ·æœ¬å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚å°½ç®¡æ•°æ®é‡æå°ï¼ˆä»… 32 å¼ å›¾åƒï¼‰ï¼Œä½†é€šè¿‡è¿ç§»å­¦ä¹ å’Œå†»ç»“ä¸»å¹²ç½‘ç»œçš„æ–¹å¼ï¼Œä»ç„¶å¯ä»¥å®ç°å¿«é€Ÿæœ‰æ•ˆçš„è®­ç»ƒä¸é¢„æµ‹ã€‚

å¦‚éœ€æ‰©å±•è‡³æ›´å¤šç±»åˆ«æˆ–æ›´å¤§è§„æ¨¡æ•°æ®é›†ï¼Œè¯·ç›¸åº”åœ°è°ƒæ•´è¾“å…¥è·¯å¾„ã€ç±»åˆ«æ•°ä»¥åŠæ¨¡å‹ç»“æ„ã€‚